{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### IS727272 - Cordero Hern√°ndez, Marco Ricardo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 4.1.6 Bike Sharing Hourly, Linear Regression, Ridge\n",
    "\n",
    "The regression model is a statistical procedure that allows a researcher to estimate the linear, or straight line, relationship that relates two or more variables.\n",
    "\n",
    "Sometimes the linear regression models tends to overfit the datasets, it causes that the model can not generalize the learning.\n",
    "\n",
    "For this reason there is an algorithm type called Regularized GD.\n",
    "\n",
    "This algorithm consists in penalizing some w's coefficients to allow the model generalize the learning. \n",
    "\n",
    "### Instructions:\n",
    "\n",
    "1. Load the Bike-sharing hourly dataset\n",
    "2. Drop the columns ['instant', 'dteday', 'casual', 'registered']\n",
    "3. Verify that there are not null values\n",
    "4. Convert to numpy matrix the attributes and the ouput 'cnt' \n",
    "5. Add the columns of number 1\n",
    "6. Split the dataset into Training and Testing sets\n",
    "7. Using the xTrain and yTrain (Training dataset) and Linear Regression function from sklearn library, obtain the model (W's). Then make predictions using the Testing dataset, and obtain the $R^2$ score of your predictions.\n",
    "8. Using Ridge function from sklearn library, obtain the model (W's) and then make predictions using the Testing dataset, and obtain the $R^2$ score of your predictions.\n",
    "9. Incrementar el valor de alfa de forma logaritmica: 10, 100, 1000, 10000, 100000, 1e6, 1e7. Graficar el comportamiento del score del ridge para cada valor de alpha"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Preparing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import math\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>instant</th>\n",
       "      <th>dteday</th>\n",
       "      <th>season</th>\n",
       "      <th>yr</th>\n",
       "      <th>mnth</th>\n",
       "      <th>hr</th>\n",
       "      <th>holiday</th>\n",
       "      <th>weekday</th>\n",
       "      <th>workingday</th>\n",
       "      <th>weathersit</th>\n",
       "      <th>temp</th>\n",
       "      <th>atemp</th>\n",
       "      <th>hum</th>\n",
       "      <th>windspeed</th>\n",
       "      <th>casual</th>\n",
       "      <th>registered</th>\n",
       "      <th>cnt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2011-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.2879</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>13</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2011-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.2727</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8</td>\n",
       "      <td>32</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>2011-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.2727</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5</td>\n",
       "      <td>27</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>2011-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.2879</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>2011-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.2879</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   instant      dteday  season  yr  mnth  hr  holiday  weekday  workingday  \\\n",
       "0        1  2011-01-01       1   0     1   0        0        6           0   \n",
       "1        2  2011-01-01       1   0     1   1        0        6           0   \n",
       "2        3  2011-01-01       1   0     1   2        0        6           0   \n",
       "3        4  2011-01-01       1   0     1   3        0        6           0   \n",
       "4        5  2011-01-01       1   0     1   4        0        6           0   \n",
       "\n",
       "   weathersit  temp   atemp   hum  windspeed  casual  registered  cnt  \n",
       "0           1  0.24  0.2879  0.81        0.0       3          13   16  \n",
       "1           1  0.22  0.2727  0.80        0.0       8          32   40  \n",
       "2           1  0.22  0.2727  0.80        0.0       5          27   32  \n",
       "3           1  0.24  0.2879  0.75        0.0       3          10   13  \n",
       "4           1  0.24  0.2879  0.75        0.0       0           1    1  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load dataset\n",
    "df_hour = pd.read_csv('./Datasets/hourly.csv')\n",
    "df_hour.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 17379 entries, 0 to 17378\n",
      "Data columns (total 17 columns):\n",
      " #   Column      Non-Null Count  Dtype  \n",
      "---  ------      --------------  -----  \n",
      " 0   instant     17379 non-null  int64  \n",
      " 1   dteday      17379 non-null  object \n",
      " 2   season      17379 non-null  int64  \n",
      " 3   yr          17379 non-null  int64  \n",
      " 4   mnth        17379 non-null  int64  \n",
      " 5   hr          17379 non-null  int64  \n",
      " 6   holiday     17379 non-null  int64  \n",
      " 7   weekday     17379 non-null  int64  \n",
      " 8   workingday  17379 non-null  int64  \n",
      " 9   weathersit  17379 non-null  int64  \n",
      " 10  temp        17379 non-null  float64\n",
      " 11  atemp       17379 non-null  float64\n",
      " 12  hum         17379 non-null  float64\n",
      " 13  windspeed   17379 non-null  float64\n",
      " 14  casual      17379 non-null  int64  \n",
      " 15  registered  17379 non-null  int64  \n",
      " 16  cnt         17379 non-null  int64  \n",
      "dtypes: float64(4), int64(12), object(1)\n",
      "memory usage: 2.3+ MB\n"
     ]
    }
   ],
   "source": [
    "# Verify that there are not null values\n",
    "df_hour.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the columns ['instant', 'dteday', 'casual', 'registered']\n",
    "\n",
    "df_hour = df_hour.drop(columns = ['instant', 'dteday', 'casual', 'registered'])\n",
    "#df_hour = df_hour.drop(['instant', 'dteday', 'casual', 'registered'], inplace = True, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape:  (17379, 12) Y shape:  (17379, 1)\n"
     ]
    }
   ],
   "source": [
    "# Convert to numpy matrix the attributes and the ouput 'cnt'\n",
    "dataset = np.array(df_hour)\n",
    "m, n = np.shape(dataset)\n",
    "x = dataset[:, 0:n-1]\n",
    "y = dataset[:, -1]\n",
    "\n",
    "# Reshape the output\n",
    "y = y.reshape(m, 1)\n",
    "print('X shape: ', np.shape(x), 'Y shape: ', np.shape(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the columns of number 1\n",
    "\n",
    "def addones(X):\n",
    "    X1 = np.array(X)\n",
    "    m, n = np.shape(X1)\n",
    "    ones = np.ones((m, 1))\n",
    "    X1 = np.concatenate((ones, X1), axis = 1)\n",
    "    \n",
    "    return X1\n",
    "\n",
    "x = addones(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of Training data:  (11643, 13) (11643, 1)\n",
      "Shape of Testing data:  (5736, 13) (5736, 1)\n"
     ]
    }
   ],
   "source": [
    "# Split the dataset into Training and Testing sets, test size of 33%, and random_state= 1\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size = 0.33, random_state = 1)\n",
    "print('Shape of Training data: ', np.shape(X_train), np.shape(y_train))\n",
    "print('Shape of Testing data: ', np.shape(X_test), np.shape(y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Normal Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error (R2): 0.3966400174284631\n",
      "W: [[ 0.00000000e+00  1.85126892e+01  7.81151861e+01  1.71585299e-01\n",
      "   7.63881341e+00 -2.70804291e+01  1.66918680e+00  3.92795159e+00\n",
      "  -2.72936547e+00  2.10019998e+01  2.96443537e+02 -1.98320492e+02\n",
      "   4.29975972e+01]]\n",
      "W0: [-24.62175314]\n",
      "[[-2.46217531e+01  1.85126892e+01  7.81151861e+01  1.71585299e-01\n",
      "   7.63881341e+00 -2.70804291e+01  1.66918680e+00  3.92795159e+00\n",
      "  -2.72936547e+00  2.10019998e+01  2.96443537e+02 -1.98320492e+02\n",
      "   4.29975972e+01]]\n"
     ]
    }
   ],
   "source": [
    "# Using the xTrain and yTrain (Training dataset) and Linear Regression function from sklearn library, obtain the model (W's). \n",
    "# Then make predictions using the Testing dataset, and obtain the  ùëÖ2  score of your predictions.\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "# Fit the data to training dataset\n",
    "reg = LinearRegression().fit(X_train, y_train)\n",
    "\n",
    "# Obtain and print the score \n",
    "Costo = reg.score(X_test, y_test)\n",
    "print(f'Error (R2): {Costo}')\n",
    "\n",
    "# Obtain and print the W's coefficients\n",
    "w = reg.coef_\n",
    "print(f'W: {w}')\n",
    "\n",
    "# Obtain and print the intercept\n",
    "intercepto = reg.intercept_\n",
    "print(f'W0: {intercepto}')\n",
    "\n",
    "# Add the intercept value to the W's array and print W\n",
    "w[0][0] = intercepto\n",
    "print(w)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implement $R^2$ Score\n",
    "\n",
    "$$R^2 = 1 - \\frac{\\sum(y_i - \\hat{y}_i)^2}{\\sum(y_i - \\bar{y})^2 }$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5736, 1)\n",
      "0.3966400174284632\n"
     ]
    }
   ],
   "source": [
    "def r2(Y, Yt):\n",
    "    \n",
    "    error = Y - Yt\n",
    "    varianza = (Y - np.average(Y)) ** 2\n",
    "    cost = 1 - (np.sum(error ** 2)) / np.sum(varianza)\n",
    "    \n",
    "    return cost\n",
    "                \n",
    "# Predictions for Testing dataset\n",
    "yt = np.dot(w, X_test.T).T\n",
    "print(np.shape(yt))\n",
    "\n",
    "# Obtain and print the R2 score\n",
    "costo = r2(y_test, yt)\n",
    "print(costo)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Gradient Descent with Regularization (Ridge)\n",
    "\n",
    "Cost function for Gradient Descent Regularized:\n",
    "$$\n",
    "J(w) = \\frac{1}{2m}\\big[\\sum_{i=1}^{m}(\\hat y^{(i)}-y^{(i)})^2+\\lambda\\sum_{j=1}^{n}w_j^2 \\big]\n",
    "$$\n",
    "\n",
    "W's update for GD Regularized:\n",
    "$$\n",
    "w_0 = w_0 - \\alpha \\frac{1}{m}\\sum_{i=1}^{m}(\\hat y^{(i)}-y^{(i)})x_0^{(i)}\n",
    "$$\n",
    "$$\n",
    "w_j = w_j - \\alpha \\frac{1}{m} \\big [ \\sum_{i=1}^{m}(\\hat y^{(i)}-y^{(i)})x_j^{(i)} + \\frac{\\lambda}{m}w_j \\big ]\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2: 0.3970991495935524\n",
      "[[ 0.00000000e+00  1.87979917e+01  7.80755631e+01  9.04443011e-02\n",
      "   7.71497657e+00 -2.68777527e+01  1.63243838e+00  4.00689450e+00\n",
      "  -3.80801447e+00  1.17850923e+02  1.82814798e+02 -1.91233474e+02\n",
      "   3.74355198e+01]]\n",
      "[-21.55152971]\n",
      "[[-2.15515297e+01  1.87979917e+01  7.80755631e+01  9.04443011e-02\n",
      "   7.71497657e+00 -2.68777527e+01  1.63243838e+00  4.00689450e+00\n",
      "  -3.80801447e+00  1.17850923e+02  1.82814798e+02 -1.91233474e+02\n",
      "   3.74355198e+01]]\n"
     ]
    }
   ],
   "source": [
    "# Linear regression con regularizacion \"Ridge\"\n",
    "# Using Ridge function from sklearn library, obtain the model (W's) and then make predictions using the Testing dataset\n",
    "# and obtain the  ùëÖ2  score of your predictions.\n",
    "\n",
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "# Define the clf method using alpha = 10\n",
    "clf = Ridge(alpha = 10.0)\n",
    "\n",
    "# Fit to the training dataset\n",
    "ridge = clf.fit(X_train, y_train)\n",
    "\n",
    "# Obtain and print the score \n",
    "Score2 = ridge.score(X_test, y_test)\n",
    "print(f'R2: {Score2}')\n",
    "\n",
    "# Obtain and print the W's coefficients\n",
    "w2 = ridge.coef_\n",
    "print(w2)\n",
    "\n",
    "# Obtain and print the intercept\n",
    "intercepto2 = ridge.intercept_\n",
    "print(intercepto2)\n",
    "\n",
    "# Add the intercept value to the W's array and print W\n",
    "w2[0][0] = intercepto2\n",
    "print(w2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5736, 1)\n",
      "0.3970991495935524\n"
     ]
    }
   ],
   "source": [
    "# Predictions for Testing dataset for Ridge algorithm\n",
    "yt2 = np.dot(w2, X_test.T).T\n",
    "print(np.shape(yt2))\n",
    "\n",
    "# Obtain and print the R2 score for Ridge Algorithm\n",
    "costo2 = r2(y_test, yt2)\n",
    "print(costo2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1ff91aaa8b0>]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Incrementar el valor de alfa de forma logaritmica: 10, 100, 1000, 10000, 100000, 1e6, 1e7\n",
    "#Graficar el comportamiento del score del ridge para cada valor de alpha\n",
    "\n",
    "alphas = [10, 100, 1000, 10000, 100000, 1e6, 1e7, 1e8]\n",
    "J = []\n",
    "\n",
    "\n",
    "for a in alphas:\n",
    "    # Define the clf method using distinct alphas\n",
    "    clf = Ridge(alpha = a)\n",
    "\n",
    "    # Fit to the training dataset\n",
    "    ridge = clf.fit(X_train, y_train)\n",
    "\n",
    "    # Obtain and print the score \n",
    "    Score = ridge.score(X_test, y_test)\n",
    "\n",
    "    # Obtain and print the W's coefficients\n",
    "    w = ridge.coef_\n",
    "\n",
    "    # Obtain and print the intercept\n",
    "    intercepto = ridge.intercept_\n",
    "\n",
    "    # Add the intercept value to the W's array and print W\n",
    "    w[0][0] = intercepto\n",
    "    \n",
    "    # Predictions for Testing dataset for Ridge algorithm\n",
    "    yt = np.dot(w, X_test.T).T\n",
    "\n",
    "    # Obtain and print the R2 score for Ridge Algorithm\n",
    "    costo = r2(y_test, yt)\n",
    "    \n",
    "    J.append(costo)\n",
    "\n",
    "    \n",
    "plt.plot(alphas, J, 'b')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TAREA\n",
    "\n",
    "1. Utilizar el dataset: https://archive.ics.uci.edu/ml/datasets/Appliances+energy+prediction, y hacer los mismos pasos. \n",
    "\n",
    "NOTA: La salida es Appliances en la columna 2, y borrar la columna de fechas de la columna 1."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
